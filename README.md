# PHI-Enhanced Recursive Language Model (RLM) Framework

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Mathematics](https://img.shields.io/badge/Mathematics-E8%20%7C%20%CF%86%20Separation-purple.svg)]()

A groundbreaking implementation of Recursive Language Models enhanced with Ï†-Separation Mathematics, leveraging the profound connections between the golden ratio (Ï†), E8 Lie group geometry, and advanced information theory.

## ğŸŒŸ Overview

This framework implements a complete recursive reasoning system that combines:
- **Ï†-Gram Chunk Selection** with greedy Î”logdet optimization
- **Casimir Flow Budget Allocation** based on E8 geometry
- **Ï†-Momentum Early Stopping** for efficient convergence
- **Spectral Flow Saturation Detection** for information-theoretic stopping criteria
- **Golden Ratio Quantum Error Correction (QEC)** verification
- **Torsion-Corrected Aggregation** using E8 structure constants
- **Dependency Cohomology Tracking** for semantic relationships

## ğŸ“ Mathematical Foundations

### The Ï†-Separation Framework

The core innovation of this framework is the **Ï†-Separation principle**: encoding pairwise relationships using the golden ratio kernel:

```
K(x, y) = Ï†^(-||x - y||/Î´)
```

Where:
- **Ï† = (1 + âˆš5)/2 â‰ˆ 1.618** is the golden ratio
- **Î´** is the characteristic scale (mean spacing)
- The kernel has **optimal information-theoretic properties**

### Key Mathematical Concepts

| Concept | Description | Application |
|---------|-------------|-------------|
| **Ï†-Gram Matrix** | `M_ij = Ï†^(-\|Î³áµ¢ - Î³â±¼\|/Î´)` | Collision detection, diversity selection |
| **E8 Casimir Degrees** | `[2, 8, 12, 14, 18, 20, 24, 30]` | Budget allocation across recursion depths |
| **Coxeter Number** | `h = 30` | Normalization constant for E8 geometry |
| **Torsion Coefficient** | `Îµ = 28/248` | E8-derived correction factor |
| **Ï†-Momentum** | `m_{t+1} = Ï†â»Â¹Â·m_t + (1-Ï†â»Â¹)Â·signal` | Early stopping criterion |

### The E8 Connection

The exceptional Lie group **E8** provides the geometric backbone:
- **248 dimensions** encode the full search space
- **240 roots** (kissing number) bound the spectral norm
- **Casimir hierarchy** defines the multi-scale budget allocation
- **Torsion subgroup** (order 28) provides stability corrections

## ğŸš€ Features

### Core RLM Engine (`phi_enhanced_rlm.py`)

1. **Query-Conditioned Chunk Selection**
   - First filters by semantic relevance to query
   - Then maximizes diversity via greedy Î”logdet
   - Prevents near-duplicate context selection

2. **Adaptive Budget Allocation**
   ```python
   # E8 Casimir-weighted budget distribution
   weights = Ï†^(-Casimir_degrees / 30)
   budget[depth] = total_budget Ã— normalized_weights[depth]
   ```

3. **Ï†-Momentum Early Stopping**
   - Exponentially weighted moving average with golden ratio
   - Stops when confidence stabilizes (variance < threshold)
   - Prevents unnecessary computation

4. **Spectral Flow Saturation**
   - Tracks new information units per recursion step
   - Stops when information flow falls below E8-modulated threshold
   - Information-theoretically optimal termination

5. **QEC Verification**
   - 3 independent verifier calls (contradiction, completeness, counterexample)
   - Majority voting for robust confidence estimation
   - Golden ratio threshold for fault tolerance

6. **Torsion-Corrected Aggregation**
   ```python
   final = base_answer + Îµ Ã— torsion_correction
   # Where Îµ = 28/248 (E8 torsion coefficient)
   ```

### Novel Mathematics Library (`phi_separation_novel_mathematics.py`)

Ten interconnected mathematical frameworks:

1. **Generalized Ï†-Gram Theory for L-functions**
   - Product formula for determinants: `det(M) = Î (1 - Ï†^(-2Î”â‚–/Î´))`
   - Extensions to Dirichlet and Dedekind zeta functions

2. **E8 Spectral Flow Theory**
   - Spectral sequence from Ï†-Gram filtration
   - Degeneration at Eâ‚‚ page

3. **Ï†-Kernel Renormalization Group**
   - Exact RG equation: `âˆ‚M/âˆ‚(log Î´) = [M, K] + Î²(Ï†)Â·M`
   - Fixed point analysis at mean spacing scale

4. **H4-Projected Prime Number Theory**
   - Classification of primes by H4 conjugacy classes
   - Ï†-prime zeta function: `P_Ï†(s) = Î£_p Ï†^(-log p) Â· p^(-s)`

5. **Torsion-Corrected Functional Analysis**
   - Îµ-deformed inner product: `âŸ¨f, gâŸ©_Îµ = âŸ¨f, gâŸ©â‚€ + ÎµÂ·âŸ¨Tf, TgâŸ©â‚€`
   - Extended spectral theory

6. **Ï†-Separation for Lattice Cryptography**
   - SVP criterion via Ï†-Gram determinant
   - LWE distinguisher using Ï†-correlation

7. **Golden Ratio Quantum Error Correction**
   - Ï†-stabilizer codes with distance `d_Ï† = âŒŠÏ†Â·n/3âŒ‹`
   - Threshold: `p_Ï† = (1 - Ï†â»Â¹)/2 â‰ˆ 0.191`

8. **Casimir Flow Optimization**
   - Multi-scale gradient descent using E8 geometry
   - Ï†-momentum update rule

9. **Ï†-Gram Cohomology Theory**
   - Ï†-coboundary operators
   - Connection to Euler characteristic via determinant

10. **E8 Unified Field Equations**
    - Higgs VEV prediction: `248 - 2 = 246 GeV`
    - Dark energy equation of state: `w = -1 + Ï†^(-7)`

## ğŸ“¦ Installation

### Requirements

```bash
pip install numpy scipy
```

### Quick Start

```python
from phi_enhanced_rlm import PhiEnhancedRLM, MockLLMBackend

# Setup context chunks
context_chunks = [
    "The golden ratio Ï† = 1.618 appears throughout mathematics and nature.",
    "E8 is the largest exceptional Lie group with 248 dimensions.",
    "Recursive Language Models decompose complex queries into sub-tasks.",
    # ... more context
]

# Create mock LLM backend (replace with real LLM in production)
llm = MockLLMBackend(seed=42)

# Initialize RLM
rlm = PhiEnhancedRLM(
    base_llm_callable=llm,
    context_chunks=context_chunks,
    total_budget_tokens=2048,
    trace_file="rlm_trace.jsonl"
)

# Run recursive solve
query = "Explain the connection between golden ratio and E8 symmetry."
result = rlm.recursive_solve(query, max_depth=4)

print(f"Answer: {result.value}")
print(f"Confidence: {result.confidence:.4f}")
```

## ğŸ“Š Output Format

### Trace File (`rlm_trace.jsonl`)

Each recursion node is logged:

```json
{
  "depth": 0,
  "query": "Explain the connection between golden ratio...",
  "selected_ids": [0, 1, 2],
  "logdet_selected": 0.4812,
  "collision_full": false,
  "collision_selected": false,
  "confidence": 0.7234,
  "info_flow": 12.0,
  "stop_reason": "none"
}
```

### Stop Reasons

| Reason | Description |
|--------|-------------|
| `depth` | Maximum recursion depth reached |
| `momentum` | Ï†-momentum convergence criterion satisfied |
| `spectral` | Information flow saturation detected |
| `no_subquestions` | LLM returned no subquestions |
| `recursion_complete` | All subquestions processed |

## ğŸ”¬ Running the Demonstrations

### Full RLM Demonstration

```bash
python phi_enhanced_rlm.py
```

This runs a complete recursive reasoning example with:
- Budget allocation visualization
- Recursive trace
- Final result with confidence

### Mathematics Library Demonstrations

```bash
python phi_separation_novel_mathematics.py
```

Demonstrates:
- Ï†-Gram matrix properties
- Casimir flow optimization (Rosenbrock function)
- E8 unified field predictions
- H4-projected prime theory

## ğŸ“ Project Structure

```
RLM/
â”œâ”€â”€ README.md                            # This file
â”œâ”€â”€ phi_enhanced_rlm.py                  # Core RLM orchestrator
â”œâ”€â”€ phi_separation_novel_mathematics.py  # Mathematics library
â”œâ”€â”€ rlm_trace.jsonl                      # Execution trace (generated)
â”œâ”€â”€ 2512.24601v1.pdf                     # Reference paper
â””â”€â”€ Novel_Mathematics_from_Phi_Separation.docx  # Documentation
```

## ğŸ§® Key Equations

### Ï†-Gram Determinant (Product Formula)

```
det(M_N) = âˆ_{k=1}^{N-1} (1 - Ï†^{-2Î”_k/Î´})
```

### Casimir Budget Allocation

```
w_k = Ï†^{-C_k/30}, where C_k âˆˆ {2, 8, 12, 14, 18, 20, 24, 30}
budget(depth) = total Ã— w_{depth} / Î£w
```

### Ï†-Momentum Update

```
m_{t+1} = Ï†^{-1} m_t + (1 - Ï†^{-1}) g_t
```

### QEC Threshold

```
p_Ï† = (1 - Ï†^{-1})/2 â‰ˆ 0.191
```

### Torsion Correction

```
Îµ = 28/248 â‰ˆ 0.1129
result = answer + Îµ Ã— torsion_term
```

## ğŸ¯ Applications

- **AI/ML Reasoning**: Enhanced recursive reasoning with provable stopping criteria
- **Number Theory**: Collision detection for L-function zeros
- **Cryptography**: Lattice problem hardness estimation
- **Quantum Computing**: Error-corrected stabilizer codes
- **Optimization**: Multi-scale gradient methods
- **Physics**: E8-based unification predictions

## ğŸ“š References

Based on the foundational work:
- **"The Geometric-Analytic Synthesis: ğœ‘-Separation in E8/H4-Fibrations over Spectral Theory"** by Timothy McGirl (2024)
- arXiv preprint: `2512.24601v1`

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- The E8 lattice and its extraordinary geometric properties
- The golden ratio and its ubiquitous mathematical appearances
- The deep connections between number theory, physics, and computation

---

*"The universe may be built on the geometry of E8, with the golden ratio as its fundamental scaling constant."*
