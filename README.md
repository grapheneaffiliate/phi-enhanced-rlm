# PHI-Enhanced Recursive Language Model (RLM) v2.0

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![API](https://img.shields.io/badge/API-FastAPI-green.svg)](https://fastapi.tiangolo.com/)

A recursive language model framework enhanced with Ï†-Separation Mathematics, featuring streaming responses, document analysis, REST API, and parallel processing.

## âœ¨ Features

- **ğŸ“¡ Streaming Output** â€” Real-time response streaming
- **ğŸ“„ PDF/DOCX Support** â€” Analyze documents directly
- **ğŸŒ Smart Web Extraction** â€” Trafilatura for clean article extraction
- **ğŸ’¾ SQLite Embedding Cache** â€” Persistent cache survives restarts
- **ğŸ”Œ REST API** â€” FastAPI with OpenAPI docs
- **ğŸ’¬ Conversation Memory** â€” Stateful chat with context
- **âš¡ Parallel Processing** â€” Process subquestions concurrently
- **ğŸ“Š Confidence Visualization** â€” See the reasoning tree
- **ğŸ”„ Comparison Mode** â€” Compare repos, URLs, or documents
- **ğŸ“ Export Reports** â€” Save analyses as markdown
- **ğŸ¨ Rich Progress** â€” Beautiful terminal UI

---

## ğŸš€ Quick Start

### 1. Install

```bash
git clone https://github.com/grapheneaffiliate/phi-enhanced-rlm.git
cd phi-enhanced-rlm
pip install -r requirements.txt
```

### 2. Configure

```bash
cp .env.template .env
# Edit .env: OPENROUTER_API_KEY=sk-or-v1-your-key
```

### 3. Run

```bash
# Interactive chat
python cli/chat.py

# REST API server
python api/server.py
# Visit: http://localhost:8000/docs
```

---

## ğŸ“ Project Structure

```
phi-enhanced-rlm/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ LICENSE                   # MIT License
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ pyproject.toml           # Package configuration
â”œâ”€â”€ .env.template            # API key template
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ src/                     # Core library
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ phi_enhanced_rlm.py      # Main RLM orchestrator
â”‚   â”œâ”€â”€ phi_separation_novel_mathematics.py  # Ï†-Math foundations
â”‚   â”œâ”€â”€ embeddings.py            # Embedding generation
â”‚   â”œâ”€â”€ cache.py                 # SQLite embedding cache
â”‚   â”œâ”€â”€ extractors.py            # PDF/DOCX/web extractors
â”‚   â”œâ”€â”€ progress.py              # Rich progress display
â”‚   â”œâ”€â”€ openrouter_backend.py    # OpenRouter LLM backend
â”‚   â””â”€â”€ async_backend.py         # Async LLM operations
â”‚
â”œâ”€â”€ cli/                     # Command-line tools
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chat.py                  # Interactive chat v2.0
â”‚   â”œâ”€â”€ run_rlm.py               # Simple query runner
â”‚   â”œâ”€â”€ repo_analyzer.py         # GitHub/URL analyzer
â”‚   â””â”€â”€ validate_rlm.py          # System validation
â”‚
â”œâ”€â”€ api/                     # REST API
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ server.py                # FastAPI server
â”‚
â”œâ”€â”€ web/                     # Web interface
â”‚   â””â”€â”€ index.html
â”‚
â”œâ”€â”€ tests/                   # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_upgrades.py
â”‚
â”œâ”€â”€ docs/                    # Documentation
â”‚   â”œâ”€â”€ 2512.24601v1.pdf         # Research paper
â”‚   â””â”€â”€ Novel_Mathematics_from_Phi_Separation.docx
â”‚
â””â”€â”€ examples/                # Example outputs
    â””â”€â”€ *.json, *.jsonl
```

---

## ğŸ’¬ Interactive Chat

```bash
python cli/chat.py
```

### Commands

| Command | Description |
|---------|-------------|
| `<question>` | Ask any question |
| `/repo owner/repo` | Analyze GitHub repository |
| `/url https://...` | Analyze web page |
| `/local ./path` | Analyze local directory |
| `/pdf path.pdf` | Analyze PDF document |
| `/doc path.docx` | Analyze Word document |
| `/image path.png` | Describe & analyze image |
| `/compare s1 s2` | Compare two sources |
| `/export file.md` | Export last analysis |
| `/history` | Show query history |
| `/stream on\|off` | Toggle streaming |
| `/trace` | Show reasoning tree |
| `/depth N` | Set recursion depth (0-10) |
| `/help` | Show all commands |
| `/quit` | Exit |

### Example

```
PHI-ENHANCED RLM INTERACTIVE CHAT v2.0
âœ“ Backend ready: anthropic/claude-3.5-sonnet

You: What is the golden ratio?

â•­â”€ PHI-RLM Response â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ The golden ratio (Ï† â‰ˆ 1.618) is...        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Confidence: 85.0%

You: /pdf research_paper.pdf
Extracting PDF...
âœ“ Analyzed 12 pages

You: /export analysis.md
âœ“ Exported to analysis.md
```

---

## ğŸ”Œ REST API

```bash
python api/server.py
# Or: uvicorn api.server:app --reload --port 8000
```

### Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/` | API info |
| `GET` | `/status` | System status |
| `GET` | `/docs` | Swagger UI |
| `POST` | `/analyze` | Analyze with RLM |
| `POST` | `/chat` | Chat with memory |
| `POST` | `/compare` | Compare sources |
| `GET` | `/history` | Query history |

### Example: Analyze

```bash
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"query": "What is E8?", "max_depth": 3}'
```

```json
{
  "answer": "E8 is the largest exceptional Lie group...",
  "confidence": 0.85,
  "depth_reached": 2,
  "chunks_used": [0, 3, 5]
}
```

---

## ğŸ“„ Document Analysis

### PDF

```bash
pip install PyMuPDF
```

```python
from src.extractors import extract_pdf_content

result = extract_pdf_content("paper.pdf")
print(f"Title: {result.title}")
print(f"Pages: {result.metadata['page_count']}")
```

### Word Documents

```bash
pip install python-docx
```

```python
from src.extractors import extract_docx_content

result = extract_docx_content("report.docx")
print(result.text)
```

---

## ğŸ’¾ Embedding Cache

Embeddings are cached in SQLite for fast repeated analysis:

```python
from src.cache import SQLiteEmbeddingCache

cache = SQLiteEmbeddingCache()
cache.set("text", "model-v1", embedding_vector)
cached = cache.get("text", "model-v1")

stats = cache.get_stats()
print(f"Hits: {stats.hits}, Entries: {stats.entry_count}")
```

Cache location: `~/.cache/phi_rlm/embeddings.db`

---

## âš¡ Parallel Processing

```python
from src.phi_enhanced_rlm import PhiEnhancedRLM

rlm = PhiEnhancedRLM(backend, context_chunks)
rlm.enable_parallel(True)  # Subquestions processed concurrently

result = rlm.recursive_solve("Complex query", max_depth=3)
```

---

## ğŸ“Š Reasoning Tree

```python
rlm = PhiEnhancedRLM(backend, context_chunks)
result = rlm.recursive_solve("Query")
rlm.print_reasoning_tree()
```

```
REASONING TREE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸŸ¢ D0: What is the golden ratio?
   Conf: 85.0% | Chunks: [0, 3, 5]
  ğŸŸ¡ D1: Mathematical definition...
     Conf: 75.0% | Stopped: momentum
  ğŸŸ¢ D1: Applications in nature...
     Conf: 80.0% | Stopped: spectral
```

---

## ğŸ”„ Comparison Mode

```bash
# In chat:
> /compare facebook/react vuejs/vue

# Or via API:
curl -X POST http://localhost:8000/compare \
  -d '{"source1": "react", "source2": "vue"}'
```

---

## ğŸ§® Mathematical Foundations

### Ï†-Separation Kernel

```
K(x, y) = Ï†^(-||x - y||/Î´)
```

### E8 Casimir Budget Allocation

```
Depth 0: 635 tokens (15.5%)
Depth 1: 577 tokens (14.1%)
...
Depth 7: 405 tokens (9.9%)
```

### QEC Threshold

```
p_Ï† = (1 - Ï†^{-1})/2 â‰ˆ 0.191
```

---

## ğŸ§ª Testing

```bash
python tests/test_upgrades.py
```

---

## ğŸ“¦ Installation (Development)

```bash
# Install with all optional dependencies
pip install -e ".[full,dev]"

# Or just core:
pip install -e .
```

---

## ğŸ¤ Contributing

Pull requests welcome! Please run tests before submitting.

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE).

---

*"The universe may be built on E8 geometry, with Ï† as its fundamental scaling constant."*
